#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ AI –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
"""

import os
import json
import logging
from datetime import datetime

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
from parser import PsychologyTodayParser
from content_analyzer import ContentAnalyzer
from article_writer import ArticleWriter
from image_prompter import ImagePrompter
from duplicate_tracker import DuplicateTracker

def test_parser():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞"""
    print("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞...")
    
    parser = PsychologyTodayParser()
    
    try:
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫
        links = parser.get_article_links(5)
        print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(links)} —Å—Å—ã–ª–æ–∫")
        
        if links:
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–π —Å—Ç–∞—Ç—å–∏
            article = parser.parse_article(links[0])
            if article:
                print(f"‚úÖ –°—Ç–∞—Ç—å—è —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–∞: {article['title'][:50]}...")
                print(f"   –°–ª–æ–≤: {article['word_count']}")
                print(f"   –¢–µ–≥–∏: {', '.join(article['tags'][:3])}")
                return article
            else:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Å—Ç–∞—Ç—å—é")
        else:
            print("‚ùå –ù–µ –ø–æ–ª—É—á–µ–Ω—ã —Å—Å—ã–ª–∫–∏")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞: {e}")
    
    return None

def test_analyzer(article):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
    print("\nüß† –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞...")
    
    if not article:
        print("‚ùå –ù–µ—Ç —Å—Ç–∞—Ç—å–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return None
    
    analyzer = ContentAnalyzer()
    
    try:
        analysis = analyzer.analyze_article(article)
        if analysis:
            print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω: {analysis['main_theme']}")
            print(f"   –¢–æ–Ω: {analysis['emotional_tone']}")
            print(f"   –§–∞–∫—Ç–æ–≤: {len(analysis['interesting_facts'])}")
            return analysis
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ç—å—é")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞: {e}")
    
    return None

def test_writer(analysis):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∏—Å–∞—Ç–µ–ª—è"""
    print("\n‚úçÔ∏è –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∏—Å–∞—Ç–µ–ª—è...")
    
    if not analysis:
        print("‚ùå –ù–µ—Ç –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –Ω–∞–ø–∏—Å–∞–Ω–∏—è")
        return None
    
    writer = ArticleWriter()
    
    try:
        article = writer.write_adapted_article(analysis)
        if article:
            print(f"‚úÖ –°—Ç–∞—Ç—å—è –Ω–∞–ø–∏—Å–∞–Ω–∞: {article['title'][:50]}...")
            print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {article['category']}")
            print(f"   –°–ª–æ–≤: {article['word_count']}")
            print(f"   –¢–µ–≥–∏: {', '.join(article['tags'])}")
            return article
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–ø–∏—Å–∞—Ç—å —Å—Ç–∞—Ç—å—é")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∏—Å–∞—Ç–µ–ª—è: {e}")
    
    return None

def test_image_prompter(article):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    print("\nüñºÔ∏è –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
    
    if not article:
        print("‚ùå –ù–µ—Ç —Å—Ç–∞—Ç—å–∏ –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
        return None
    
    prompter = ImagePrompter()
    
    try:
        image_url = prompter.get_image_for_article(article)
        if image_url:
            print(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ: {image_url}")
            return image_url
        else:
            print("‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (–≤–æ–∑–º–æ–∂–Ω–æ, –Ω–µ—Ç API –∫–ª—é—á–∞)")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–º–ø—Ç–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {e}")
    
    return None

def test_duplicate_tracker():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç—Ä–µ–∫–µ—Ä–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
    print("\nüìù –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç—Ä–µ–∫–µ—Ä–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤...")
    
    tracker = DuplicateTracker("test_used_links.json")
    
    try:
        # –¢–µ—Å—Ç–æ–≤—ã–µ —Å—Å—ã–ª–∫–∏
        test_links = [
            "https://example.com/test1",
            "https://example.com/test2"
        ]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤—ã–µ —Å—Å—ã–ª–∫–∏
        new_links = tracker.filter_new_links(test_links)
        print(f"‚úÖ –ù–æ–≤—ã–µ —Å—Å—ã–ª–∫–∏: {len(new_links)}")
        
        # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ
        tracker.mark_multiple_as_used(test_links)
        print("‚úÖ –°—Å—ã–ª–∫–∏ –ø–æ–º–µ—á–µ–Ω—ã –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–Ω–æ–≤–∞
        new_links = tracker.filter_new_links(test_links)
        print(f"‚úÖ –ù–æ–≤—ã–µ —Å—Å—ã–ª–∫–∏ –ø–æ—Å–ª–µ –ø–æ–º–µ—Ç–∫–∏: {len(new_links)}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = tracker.get_stats()
        print(f"‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats['total_used_links']} –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö —Å—Å—ã–ª–æ–∫")
        
        # –û—á–∏—Å—Ç–∫–∞
        if os.path.exists("test_used_links.json"):
            os.remove("test_used_links.json")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–µ–∫–µ—Ä–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {e}")

def test_full_pipeline():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
    print("\nüöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    if not os.getenv('OPENAI_API_KEY'):
        print("‚ùå –ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω OPENAI_API_KEY")
        return
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
    article = test_parser()
    if not article:
        return
    
    analysis = test_analyzer(article)
    if not analysis:
        return
    
    adapted_article = test_writer(analysis)
    if not adapted_article:
        return
    
    image_url = test_image_prompter(adapted_article)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    result = {
        'original_article': article,
        'analysis': analysis,
        'adapted_article': adapted_article,
        'image_url': image_url,
        'test_timestamp': datetime.now().isoformat()
    }
    
    filename = f"test_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {filename}")
    print("üéâ –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç!")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï AI –ü–†–û–¶–ï–°–°–û–†–ê –ü–°–ò–•–û–õ–û–ì–ò–ß–ï–°–ö–ò–• –°–¢–ê–¢–ï–ô")
    print("=" * 60)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(level=logging.WARNING)  # –£–º–µ–Ω—å—à–∞–µ–º –≤—ã–≤–æ–¥ –ª–æ–≥–æ–≤
    
    try:
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        test_duplicate_tracker()
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω
        test_full_pipeline()
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
    
    print("\nüèÅ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

if __name__ == "__main__":
    main()
