#!/usr/bin/env python3
"""
–û—Ñ–ª–∞–π–Ω —Ç–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –±–µ–∑ OpenAI API
"""

import os
import sys
import json
import logging
from datetime import datetime

def test_imports():
    """–¢–µ—Å—Ç –∏–º–ø–æ—Ä—Ç–∞ –≤—Å–µ—Ö –º–æ–¥—É–ª–µ–π"""
    print("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π...")
    
    try:
        from parser import PsychologyTodayParser
        print("‚úÖ parser.py - OK")
    except Exception as e:
        print(f"‚ùå parser.py - –û–®–ò–ë–ö–ê: {e}")
        return False
    
    try:
        from content_analyzer import ContentAnalyzer
        print("‚úÖ content_analyzer.py - OK")
    except Exception as e:
        print(f"‚ùå content_analyzer.py - –û–®–ò–ë–ö–ê: {e}")
        return False
    
    try:
        from article_writer import ArticleWriter
        print("‚úÖ article_writer.py - OK")
    except Exception as e:
        print(f"‚ùå article_writer.py - –û–®–ò–ë–ö–ê: {e}")
        return False
    
    try:
        from image_prompter import ImagePrompter
        print("‚úÖ image_prompter.py - OK")
    except Exception as e:
        print(f"‚ùå image_prompter.py - –û–®–ò–ë–ö–ê: {e}")
        return False
    
    try:
        from duplicate_tracker import DuplicateTracker
        print("‚úÖ duplicate_tracker.py - OK")
    except Exception as e:
        print(f"‚ùå duplicate_tracker.py - –û–®–ò–ë–ö–ê: {e}")
        return False
    
    try:
        from new_ai_processor import PsychologyArticleProcessor
        print("‚úÖ new_ai_processor.py - OK")
    except Exception as e:
        print(f"‚ùå new_ai_processor.py - –û–®–ò–ë–ö–ê: {e}")
        return False
    
    try:
        from integration_script import SiteIntegration
        print("‚úÖ integration_script.py - OK")
    except Exception as e:
        print(f"‚ùå integration_script.py - –û–®–ò–ë–ö–ê: {e}")
        return False
    
    return True

def test_parser():
    """–¢–µ—Å—Ç –ø–∞—Ä—Å–µ—Ä–∞"""
    print("\nüì∞ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞...")
    
    try:
        from parser import PsychologyTodayParser
        parser = PsychologyTodayParser()
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫
        print("–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Å—Ç–∞—Ç—å–∏...")
        links = parser.get_article_links()
        
        if links:
            print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(links)} —Å—Å—ã–ª–æ–∫")
            print(f"–ü–µ—Ä–≤—ã–µ 3 —Å—Å—ã–ª–∫–∏:")
            for i, link in enumerate(links[:3], 1):
                print(f"  {i}. {link}")
            return True
        else:
            print("‚ö†Ô∏è –°—Å—ã–ª–∫–∏ –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã (–≤–æ–∑–º–æ–∂–Ω–æ, –ø—Ä–æ–±–ª–µ–º–∞ —Å —Å–µ—Ç—å—é)")
            return False
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞: {e}")
        return False

def test_duplicate_tracker():
    """–¢–µ—Å—Ç —Ç—Ä–µ–∫–µ—Ä–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
    print("\nüîÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç—Ä–µ–∫–µ—Ä–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤...")
    
    try:
        from duplicate_tracker import DuplicateTracker
        tracker = DuplicateTracker()
        
        test_urls = [
            "https://www.psychologytoday.com/test-article-1",
            "https://www.psychologytoday.com/test-article-2",
            "https://www.psychologytoday.com/test-article-1"  # –î—É–±–ª–∏–∫–∞—Ç
        ]
        
        for url in test_urls:
            if not tracker.is_used(url):
                print(f"‚úÖ URL –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è: {url}")
                tracker.mark_as_used(url)
                print(f"‚úÖ URL –¥–æ–±–∞–≤–ª–µ–Ω: {url}")
            else:
                print(f"‚ö†Ô∏è URL —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è: {url}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = tracker.get_stats()
        print(f"‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats}")
        
        return True
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–µ–∫–µ—Ä–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {e}")
        return False

def test_integration():
    """–¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å —Å–∞–π—Ç–æ–º"""
    print("\nüåê –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å —Å–∞–π—Ç–æ–º...")
    
    try:
        from integration_script import SiteIntegration
        integrator = SiteIntegration("https://cherkas-therapy.ru")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —Å–∞–π—Ç—É
        print("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ —Å–∞–π—Ç—É...")
        if integrator.test_connection():
            print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —Å–∞–π—Ç—É - OK")
        else:
            print("‚ö†Ô∏è –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —Å–∞–π—Ç—É –Ω–µ —É–¥–∞–ª–æ—Å—å")
            
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏: {e}")
        return False

def test_file_structure():
    """–¢–µ—Å—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–æ–≤"""
    print("\nüìÅ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–æ–≤...")
    
    required_files = [
        'config.env',
        'requirements.txt',
        'parser.py',
        'content_analyzer.py',
        'article_writer.py',
        'image_prompter.py',
        'duplicate_tracker.py',
        'new_ai_processor.py',
        'integration_script.py'
    ]
    
    missing_files = []
    for file in required_files:
        if not os.path.exists(file):
            missing_files.append(file)
        else:
            print(f"‚úÖ {file} - –Ω–∞–π–¥–µ–Ω")
    
    if missing_files:
        print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∞–π–ª—ã: {', '.join(missing_files)}")
        return False
    
    return True

def test_config_files():
    """–¢–µ—Å—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    print("\nüîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º config.env
    if os.path.exists('config.env'):
        print("‚úÖ config.env - –Ω–∞–π–¥–µ–Ω")
        try:
            with open('config.env', 'r', encoding='utf-8') as f:
                content = f.read()
                if 'OPENAI_API_KEY' in content:
                    print("‚úÖ OPENAI_API_KEY - –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
                else:
                    print("‚ö†Ô∏è OPENAI_API_KEY - –Ω–µ –Ω–∞–π–¥–µ–Ω")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è config.env: {e}")
            return False
    else:
        print("‚ùå config.env - –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º requirements.txt
    if os.path.exists('requirements.txt'):
        print("‚úÖ requirements.txt - –Ω–∞–π–¥–µ–Ω")
        try:
            with open('requirements.txt', 'r', encoding='utf-8') as f:
                content = f.read()
                required_packages = ['requests', 'beautifulsoup4', 'openai', 'python-dotenv']
                for package in required_packages:
                    if package in content:
                        print(f"‚úÖ {package} - –≤ requirements.txt")
                    else:
                        print(f"‚ö†Ô∏è {package} - –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ requirements.txt")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è requirements.txt: {e}")
            return False
    else:
        print("‚ùå requirements.txt - –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False
    
    return True

def test_demo_data():
    """–¢–µ—Å—Ç —Å –¥–µ–º–æ –¥–∞–Ω–Ω—ã–º–∏"""
    print("\nüé≠ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –¥–µ–º–æ –¥–∞–Ω–Ω—ã–º–∏...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥–µ–º–æ —Ñ–∞–π–ª
    demo_files = [f for f in os.listdir('.') if f.startswith('psychology_articles_demo_') and f.endswith('.json')]
    
    if demo_files:
        demo_file = demo_files[0]
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω –¥–µ–º–æ —Ñ–∞–π–ª: {demo_file}")
        
        try:
            with open(demo_file, 'r', encoding='utf-8') as f:
                demo_data = json.load(f)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–∞–π–ª–∞
            if isinstance(demo_data, dict) and 'articles' in demo_data:
                articles = demo_data['articles']
                if isinstance(articles, list) and len(articles) > 0:
                    article = articles[0]
                    print(f"‚úÖ –î–µ–º–æ —Å—Ç–∞—Ç—å—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                    print(f"  –ó–∞–≥–æ–ª–æ–≤–æ–∫: {article.get('title', '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω')}")
                    print(f"  –î–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {len(article.get('content', ''))} —Å–∏–º–≤–æ–ª–æ–≤")
                    print(f"  –¢–µ–≥–∏: {', '.join(article.get('tags', []))}")
                    print(f"  –í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π –≤ —Ñ–∞–π–ª–µ: {len(articles)}")
                    return True
                else:
                    print("‚ùå –î–µ–º–æ —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç–∞—Ç–µ–π")
                    return False
            elif isinstance(demo_data, list) and len(demo_data) > 0:
                article = demo_data[0]
                print(f"‚úÖ –î–µ–º–æ —Å—Ç–∞—Ç—å—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç)")
                print(f"  –ó–∞–≥–æ–ª–æ–≤–æ–∫: {article.get('title', '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω')}")
                print(f"  –î–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {len(article.get('content', ''))} —Å–∏–º–≤–æ–ª–æ–≤")
                print(f"  –¢–µ–≥–∏: {', '.join(article.get('tags', []))}")
                return True
            else:
                print("‚ùå –î–µ–º–æ —Ñ–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π")
                return False
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –¥–µ–º–æ —Ñ–∞–π–ª–∞: {e}")
            return False
    else:
        print("‚ö†Ô∏è –î–µ–º–æ —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return True  # –ù–µ –∫—Ä–∏—Ç–∏—á–Ω–æ

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –ó–ê–ü–£–°–ö –û–§–õ–ê–ô–ù –¢–ï–°–¢–û–í–û–ì–û –¶–ò–ö–õ–ê")
    print("=" * 50)
    
    tests = [
        ("–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤", test_file_structure),
        ("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã", test_config_files),
        ("–ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª–µ–π", test_imports),
        ("–ü–∞—Ä—Å–µ—Ä", test_parser),
        ("–¢—Ä–µ–∫–µ—Ä –¥—É–±–ª–∏–∫–∞—Ç–æ–≤", test_duplicate_tracker),
        ("–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è", test_integration),
        ("–î–µ–º–æ –¥–∞–Ω–Ω—ã–µ", test_demo_data)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–µ '{test_name}': {e}")
            results.append((test_name, False))
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print("\n" + "="*50)
    print("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
    print("="*50)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "‚úÖ –ü–†–û–ô–î–ï–ù" if result else "‚ùå –ü–†–û–í–ê–õ–ï–ù"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç: {passed}/{total} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ")
    
    if passed == total:
        print("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´! –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ.")
    elif passed >= total * 0.8:
        print("‚ö†Ô∏è –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ. –°–∏—Å—Ç–µ–º–∞ —á–∞—Å—Ç–∏—á–Ω–æ –≥–æ—Ç–æ–≤–∞.")
    else:
        print("‚ùå –ú–Ω–æ–≥–æ —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–≤–∞–ª–µ–Ω–æ. –¢—Ä–µ–±—É–µ—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞.")
    
    print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print("1. –î–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è AI –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω—É–∂–µ–Ω VPN")
    print("2. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ OpenAI API –∫–ª—é—á –Ω–∞—Å—Ç—Ä–æ–µ–Ω –≤ config.env")
    print("3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
