#!/usr/bin/env python3
"""
–ù–æ–≤—ã–π AI –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å—Ç–∞—Ç–µ–π
–Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å Psychology Today
"""

import os
import json
import logging
import time
from datetime import datetime
from typing import List, Dict, Optional
from dotenv import load_dotenv

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à–∏ –º–æ–¥—É–ª–∏
from parser import PsychologyTodayParser
from content_analyzer import ContentAnalyzer
from article_writer import ArticleWriter
from image_prompter import ImagePrompter
from duplicate_tracker import DuplicateTracker

load_dotenv()

class PsychologyArticleProcessor:
    def __init__(self):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.parser = PsychologyTodayParser()
        self.analyzer = ContentAnalyzer()
        self.writer = ArticleWriter()
        self.image_prompter = ImagePrompter()
        self.duplicate_tracker = DuplicateTracker()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
        self.max_articles_per_day = 3
        self.min_word_count = 12000  # –ú–∏–Ω–∏–º—É–º 12,000 —Å–∏–º–≤–æ–ª–æ–≤ –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤
        self.max_word_count = 18000  # –ú–∞–∫—Å–∏–º—É–º 18,000 —Å–∏–º–≤–æ–ª–æ–≤ –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('psychology_processor.log'),
                logging.StreamHandler()
            ]
        )
    
    def process_daily_articles(self) -> List[Dict]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç–∞—Ç–µ–π"""
        logging.info("üöÄ –ù–∞—á–∏–Ω–∞—é –µ–∂–µ–¥–Ω–µ–≤–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É —Å—Ç–∞—Ç–µ–π")
        
        try:
            # 1. –ü–∞—Ä—Å–∏–Ω–≥ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–µ–π
            logging.info("üì∞ –≠—Ç–∞–ø 1: –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç–∞—Ç–µ–π —Å Psychology Today")
            raw_articles = self.parser.get_relevant_articles(self.max_articles_per_day * 2)
            
            if not raw_articles:
                logging.warning("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π")
                return []
            
            # 2. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–º —Å—Å—ã–ª–∫–∞–º
            logging.info("üîç –≠—Ç–∞–ø 2: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π")
            new_articles = []
            for article in raw_articles:
                if not self.duplicate_tracker.is_used(article['url']):
                    new_articles.append(article)
                else:
                    logging.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—É—é —Å—Ç–∞—Ç—å—é: {article['title'][:50]}...")
            
            if not new_articles:
                logging.warning("‚ùå –í—Å–µ —Å—Ç–∞—Ç—å–∏ —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã")
                return []
            
            # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            new_articles = new_articles[:self.max_articles_per_day]
            logging.info(f"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ {len(new_articles)} –Ω–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            
            # 3. –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–µ–π –¥–µ—à–µ–≤–æ–π –º–æ–¥–µ–ª—å—é
            logging.info("üß† –≠—Ç–∞–ø 3: –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–µ–π")
            analyses = self.analyzer.analyze_multiple_articles(new_articles)
            
            if not analyses:
                logging.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ç—å–∏")
                return []
            
            # 4. –°–æ–∑–¥–∞–Ω–∏–µ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
            logging.info("‚úçÔ∏è –≠—Ç–∞–ø 4: –ù–∞–ø–∏—Å–∞–Ω–∏–µ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π")
            articles = self.writer.write_multiple_articles(analyses)
            
            if not articles:
                logging.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–ø–∏—Å–∞—Ç—å —Å—Ç–∞—Ç—å–∏")
                return []
            
            # 5. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –æ–±—ä–µ–º—É
            logging.info("üìè –≠—Ç–∞–ø 5: –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—ä–µ–º–∞ —Å—Ç–∞—Ç–µ–π")
            filtered_articles = []
            for article in articles:
                word_count = article['word_count']
                if self.min_word_count <= word_count <= self.max_word_count:
                    filtered_articles.append(article)
                    logging.info(f"‚úÖ –°—Ç–∞—Ç—å—è '{article['title'][:50]}...' - {word_count} —Å–∏–º–≤–æ–ª–æ–≤")
                else:
                    logging.warning(f"‚ö†Ô∏è –°—Ç–∞—Ç—å—è '{article['title'][:50]}...' –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –ø–æ –æ–±—ä–µ–º—É: {word_count} —Å–∏–º–≤–æ–ª–æ–≤")
            
            if not filtered_articles:
                logging.error("‚ùå –ù–µ—Ç —Å—Ç–∞—Ç–µ–π –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –æ–±—ä–µ–º–∞")
                return []
            
            # 6. –ü–æ–¥–±–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            logging.info("üñºÔ∏è –≠—Ç–∞–ø 6: –ü–æ–¥–±–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            articles_with_images = self.image_prompter.get_images_for_articles(filtered_articles)
            
            # 7. –ü–æ–º–µ—á–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ
            logging.info("üìù –≠—Ç–∞–ø 7: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö —Å—Å—ã–ª–æ–∫")
            used_urls = [analysis['original_url'] for analysis in analyses]
            self.duplicate_tracker.mark_multiple_as_used(used_urls)
            
            # 8. –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            for article in articles_with_images:
                article['created_at'] = datetime.now().isoformat()
                article['source'] = 'Psychology Today'
                article['processing_date'] = datetime.now().strftime('%Y-%m-%d')
            
            logging.info(f"üéâ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(articles_with_images)} —Å—Ç–∞—Ç–µ–π")
            return articles_with_images
            
        except Exception as e:
            logging.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç–∞—Ç–µ–π: {e}")
            return []
    
    def save_articles_to_file(self, articles: List[Dict], filename: str = None) -> str:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç–∞—Ç—å–∏ –≤ —Ñ–∞–π–ª"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"psychology_articles_{timestamp}.json"
        
        try:
            data = {
                'generated_at': datetime.now().isoformat(),
                'total_articles': len(articles),
                'articles': articles
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logging.info(f"üíæ –°—Ç–∞—Ç—å–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {filename}")
            return filename
            
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Å—Ç–∞—Ç–µ–π: {e}")
            return None
    
    def get_processing_stats(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        duplicate_stats = self.duplicate_tracker.get_stats()
        
        return {
            'duplicate_tracker': duplicate_stats,
            'max_articles_per_day': self.max_articles_per_day,
            'word_count_range': f"{self.min_word_count}-{self.max_word_count}",
            'components_initialized': {
                'parser': self.parser is not None,
                'analyzer': self.analyzer is not None,
                'writer': self.writer is not None,
                'image_prompter': self.image_prompter is not None,
                'duplicate_tracker': self.duplicate_tracker is not None
            }
        }
    
    def run_daily_processing(self):
        """–ó–∞–ø—É—Å—Ç–∏—Ç—å –µ–∂–µ–¥–Ω–µ–≤–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É"""
        logging.info("üåÖ –ó–∞–ø—É—Å–∫ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç–∞—Ç–µ–π")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = self.get_processing_stats()
        logging.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {json.dumps(stats, ensure_ascii=False, indent=2)}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç—å–∏
        articles = self.process_daily_articles()
        
        if articles:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
            filename = self.save_articles_to_file(articles)
            
            # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç
            logging.info("üìã –û–¢–ß–ï–¢ –û–ë –û–ë–†–ê–ë–û–¢–ö–ï:")
            for i, article in enumerate(articles, 1):
                logging.info(f"  {i}. {article['title']}")
                logging.info(f"     –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {article['category']}")
                logging.info(f"     –°–ª–æ–≤: {article['word_count']}")
                logging.info(f"     –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {'‚úÖ' if article.get('featured_image') else '‚ùå'}")
                logging.info(f"     –¢–µ–≥–∏: {', '.join(article['tags'])}")
            
            logging.info(f"üíæ –í—Å–µ —Å—Ç–∞—Ç—å–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {filename}")
            return articles
        else:
            logging.warning("‚ö†Ô∏è –°—Ç–∞—Ç—å–∏ –Ω–µ –±—ã–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã")
            return []

def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞"""
    processor = PsychologyArticleProcessor()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    required_env_vars = ['OPENAI_API_KEY']
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    
    if missing_vars:
        logging.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è: {', '.join(missing_vars)}")
        return
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
    articles = processor.run_daily_processing()
    
    if articles:
        print(f"\nüéâ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(articles)} —Å—Ç–∞—Ç–µ–π!")
        print("üìÅ –°—Ç–∞—Ç—å–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ JSON —Ñ–∞–π–ª")
    else:
        print("\n‚ö†Ô∏è –°—Ç–∞—Ç—å–∏ –Ω–µ –±—ã–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã")
        print("üìã –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–µ–π")

if __name__ == "__main__":
    main()
